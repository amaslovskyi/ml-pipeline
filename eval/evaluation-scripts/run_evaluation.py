#!/usr/bin/env python3
"""
Simple evaluation runner - runs all tests and generates final report
"""

import os
import sys
import subprocess
import time
from datetime import datetime

def run_command(command, description, timeout=300):
    """Run a command with timeout and error handling"""
    print(f"\nğŸ”„ {description}")
    print(f"ğŸ’» Running: {command}")
    print("-" * 50)
    
    try:
        start_time = time.time()
        result = subprocess.run(
            command.split(), 
            capture_output=True, 
            text=True, 
            timeout=timeout
        )
        duration = time.time() - start_time
        
        if result.returncode == 0:
            print(result.stdout)
            print(f"âœ… Completed in {duration:.1f}s")
            return True, result.stdout
        else:
            print(f"âŒ Error: {result.stderr}")
            return False, result.stderr
            
    except subprocess.TimeoutExpired:
        print(f"â±ï¸ Timeout after {timeout}s")
        return False, "Timeout"
    except Exception as e:
        print(f"âŒ Exception: {str(e)}")
        return False, str(e)

def check_requirements():
    """Check if all requirements are met"""
    print("ğŸ” Checking Requirements")
    print("=" * 30)
    
    # Check model files
    model_path = os.path.expanduser("~/Downloads/qwen-devops-model")
    if os.path.exists(model_path):
        print("âœ… Model files found")
    else:
        print("âŒ Model files not found at ~/Downloads/qwen-devops-model")
        return False
    
    # Check Python packages
    try:
        import torch
        import transformers
        import peft
        print("âœ… Python packages available")
    except ImportError as e:
        print(f"âŒ Missing package: {e}")
        return False
    
    # Check system resources
    try:
        import psutil
        available_gb = psutil.virtual_memory().available / (1024**3)
        if available_gb >= 20:
            print(f"âœ… Sufficient RAM: {available_gb:.1f}GB")
        else:
            print(f"âš ï¸ Low RAM: {available_gb:.1f}GB (need 20GB+)")
    except:
        print("âš ï¸ Cannot check RAM")
    
    return True

def run_full_evaluation():
    """Run complete evaluation suite"""
    
    print("ğŸ”¬ DevOps Model Evaluation Suite")
    print("=" * 40)
    print(f"ğŸ•’ Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if not check_requirements():
        print("âŒ Requirements not met. Exiting.")
        return
    
    results = {}
    
    # 1. System Analysis
    success, output = run_command(
        "python3 laptop_performance_analysis.py",
        "System Compatibility Analysis",
        timeout=60
    )
    results["system_analysis"] = success
    
    # 2. Quick Performance Test
    success, output = run_command(
        "python3 quick_devops_test.py", 
        "Quick DevOps Performance Test",
        timeout=600
    )
    results["quick_test"] = success
    if success and "Average Accuracy:" in output:
        # Extract accuracy score
        try:
            accuracy_line = [line for line in output.split('\n') if 'Average Accuracy:' in line][0]
            accuracy = float(accuracy_line.split(':')[1].strip())
            results["accuracy"] = accuracy
        except:
            results["accuracy"] = None
    
    # 3. Model Comparison (if Ollama available)
    print("\nğŸ” Checking for Ollama and base model...")
    try:
        ollama_check = subprocess.run(["ollama", "list"], capture_output=True, text=True)
        if ollama_check.returncode == 0 and "qwen3:8b" in ollama_check.stdout:
            print("âœ… Ollama and qwen3:8b found")
            success, output = run_command(
                "python3 model_comparison.py",
                "Model Comparison vs Base Qwen3",
                timeout=900
            )
            results["comparison"] = success
        else:
            print("âš ï¸ Ollama or qwen3:8b not available, skipping comparison")
            results["comparison"] = "skipped"
    except:
        print("âš ï¸ Ollama not available, skipping comparison")
        results["comparison"] = "skipped"
    
    # 4. Generate Final Report
    success, output = run_command(
        "python3 performance_report.py",
        "Generate Performance Report",
        timeout=60
    )
    results["report"] = success
    
    # Summary
    print("\n" + "=" * 50)
    print("ğŸ“Š EVALUATION SUMMARY")
    print("=" * 50)
    
    total_tests = sum(1 for v in results.values() if v is True)
    print(f"âœ… Tests Completed: {total_tests}")
    
    if results.get("system_analysis"):
        print("âœ… System analysis completed")
    
    if results.get("quick_test"):
        accuracy = results.get("accuracy")
        if accuracy:
            if accuracy >= 0.7:
                rating = "ğŸ† Excellent"
            elif accuracy >= 0.6:
                rating = "âœ… Good"
            elif accuracy >= 0.5:
                rating = "âš ï¸ Fair"
            else:
                rating = "âŒ Needs Work"
            print(f"âœ… Quick test: {accuracy:.2f} accuracy ({rating})")
        else:
            print("âœ… Quick test completed")
    
    if results.get("comparison") == True:
        print("âœ… Model comparison completed")
    elif results.get("comparison") == "skipped":
        print("âš ï¸ Model comparison skipped (Ollama unavailable)")
    
    if results.get("report"):
        print("âœ… Performance report generated")
    
    # Recommendations
    print(f"\nğŸ’¡ RECOMMENDATIONS")
    print("-" * 20)
    
    if results.get("accuracy"):
        accuracy = results["accuracy"]
        if accuracy >= 0.7:
            print("ğŸ‰ Excellent performance! Ready for production use.")
        elif accuracy >= 0.6:
            print("âœ… Good performance! Ready for internal team use.")
            print("ğŸ¯ Consider additional training for weak areas.")
        elif accuracy >= 0.5:
            print("âš ï¸ Fair performance. Good for basic DevOps assistance.")
            print("ğŸ“š Recommend additional training data.")
        else:
            print("âŒ Performance needs improvement.")
            print("ğŸ”§ Consider retraining with more diverse data.")
    
    print(f"\nğŸ“ Check generated files:")
    print("   - Performance report JSON")
    print("   - Comparison results (if available)")
    print("   - Individual test outputs")
    
    print(f"\nğŸ•’ Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    run_full_evaluation()
