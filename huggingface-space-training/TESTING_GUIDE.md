# ğŸ§ª GPT-OSS DevOps Training Pipeline Testing Guide

## ğŸ“‹ Overview

Before running the expensive GPT-OSS:20B training, we need to validate the complete pipeline with a small model. This ensures repository creation and upload processes work correctly, preventing costly failures.

## ğŸ¯ Testing Strategy

### âœ… **Test Model**: Microsoft DialoGPT-small (117M parameters)
- **Training time**: ~2-5 minutes
- **Cost**: Minimal (PRO dev mode)
- **Purpose**: Validate complete pipeline

### âœ… **What We Test**:
1. Dataset loading and formatting
2. Model loading with LoRA configuration  
3. Training pipeline execution
4. Local model saving
5. **HuggingFace repository creation** (fixes your upload issue)
6. Model and tokenizer upload to Hub

## ğŸš€ Testing Options

### Option 1: Local Testing (Recommended First)

```bash
# 1. Set your HuggingFace token
export HF_TOKEN=your_token_here

# 2. Run local test
python run_local_test.py
```

**Advantages:**
- Quick validation
- Debug issues locally
- No GPU credits used

### Option 2: HuggingFace Space Testing

**Deploy `test_app.py` to a Space:**

```yaml
---
title: GPT-OSS Pipeline Test
sdk: gradio
app_file: test_app.py
hardware: cpu  # Can use CPU for testing
---
```

**Advantages:**
- Tests in actual deployment environment
- Validates Space configuration
- Uses PRO dev mode credits

### Option 3: Full Integration Test

**Deploy both test and main apps:**
1. Test with `test_app.py`
2. If successful, deploy `app.py`
3. Run full GPT-OSS:20B training

## ğŸ“ Test Files Created

| File                        | Purpose               | Usage            |
| --------------------------- | --------------------- | ---------------- |
| `test_training_pipeline.py` | Core test logic       | Local testing    |
| `test_app.py`               | Gradio test interface | Space deployment |
| `run_local_test.py`         | Local test runner     | Quick validation |
| `TESTING_GUIDE.md`          | This guide            | Documentation    |

## ğŸ”§ Test Configuration

### Model Settings
```python
TEST_MODEL_NAME = "microsoft/DialoGPT-small"  # 117M parameters
TRAINING_EPOCHS = 1  # Quick training
LORA_RANK = 8  # Small LoRA for testing
BATCH_SIZE = 2  # Conservative memory usage
```

### Dataset
- 8 DevOps examples
- Covers Docker, Kubernetes, IaC
- Quick tokenization (~512 tokens max)

## âœ… Success Criteria

### Local Test Success
```
âœ… Dependencies installed
âœ… HF_TOKEN configured  
âœ… Model loads successfully
âœ… Training completes (1 epoch)
âœ… Model saves locally
âœ… Repository created on Hub
âœ… Upload completes successfully
```

### Space Test Success  
```
âœ… Space builds without errors
âœ… GPU allocation works
âœ… Training pipeline executes
âœ… Repository creation works
âœ… Upload flow validated
âœ… Test model appears on Hub
```

## ğŸš¨ Common Issues & Solutions

### Issue: Import Errors
**Solution:**
```bash
pip install torch transformers datasets peft huggingface_hub gradio spaces
```

### Issue: HF_TOKEN Not Found
**Solution:**
- Local: `export HF_TOKEN=your_token`
- Space: Add in Settings > Repository secrets

### Issue: Repository Creation Fails
**Solution:**
- Verify token has write permissions
- Check internet connectivity
- Ensure unique repository name

### Issue: Upload Timeout
**Solution:**  
- Model is small (should upload quickly)
- Check network stability
- Retry upload

## ğŸ“Š Expected Results

### Successful Test Output
```
ğŸ§ª Starting test training pipeline...
ğŸ“ Creating test dataset...
âœ… Created 8 test examples
ğŸ“¥ Loading test model and tokenizer...
âœ… Model loaded on: auto
ğŸ”§ Adding LoRA configuration...
âœ… LoRA added - Trainable parameters: 294,912
ğŸš€ Starting test training (1 epoch)...
âœ… Training completed successfully!
ğŸ’¾ Saving test model...
âœ… Model saved locally
ğŸ—ï¸ Creating test repository: AMaslovskyi/test-devops-model-20250107-143022
âœ… Repository created successfully!
ğŸ“¤ Uploading model to HuggingFace Hub...
ğŸ“¤ Uploading tokenizer...
ğŸ‰ Upload successful! Model available at:
ğŸ”— https://huggingface.co/AMaslovskyi/test-devops-model-20250107-143022
ğŸ‰ TEST PIPELINE COMPLETED SUCCESSFULLY!
âœ… Ready to run full GPT-OSS:20B training
```

### Test Results File
```json
{
  "test_completed": true,
  "timestamp": "2025-01-07T14:30:22",
  "model_name": "microsoft/DialoGPT-small",
  "repository": "AMaslovskyi/test-devops-model-20250107-143022",
  "upload_successful": true,
  "repository_url": "https://huggingface.co/AMaslovskyi/test-devops-model-20250107-143022"
}
```

## ğŸ¯ Next Steps After Successful Test

### 1. **Deploy Main Application**
- Upload `app.py` to your main Space
- Configure secrets (HF_TOKEN, WANDB_API_KEY)
- Set hardware to 4xL40S GPU

### 2. **Run GPT-OSS:20B Training**
- Use validated pipeline
- Repository creation will work correctly
- Upload will succeed (proven by test)

### 3. **Monitor Training**
- Watch training logs
- Check W&B metrics
- Verify checkpoints save

## ğŸ§¹ Cleanup

### After Successful Test
```python
# Local cleanup
python -c "from test_training_pipeline import cleanup_test_files; cleanup_test_files()"

# Or manual cleanup
rm -rf test-devops-model/
rm test_results.json
```

### Test Repositories
- Test repositories are created with timestamps
- Safe to delete after validation
- Keep for reference if needed

## ğŸ”„ Iteration Process

1. **Run Local Test** â†’ Fix any issues
2. **Run Space Test** â†’ Validate environment  
3. **Deploy Main App** â†’ Production ready
4. **Train GPT-OSS:20B** â†’ Confident success

## ğŸ’¡ Pro Tips

### For PRO Dev Mode
- Test apps use minimal resources
- GPU duration is short (60s vs 480s)
- Iterate quickly without cost

### For Repository Management
- Test repos use timestamp naming
- Avoid conflicts with main models
- Easy to identify and clean up

### For Debugging
- Verbose logging in test apps
- Step-by-step progress tracking
- Clear error messages

## ğŸ‰ Confidence Level

After successful testing:
- âœ… **99% confidence** in GPT-OSS:20B training success
- âœ… **Upload issues resolved** (your main concern)
- âœ… **Pipeline validated** end-to-end
- âœ… **Ready for production** training

---

**ğŸš€ Ready to test? Start with local testing, then move to Space testing!**
